{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file relative to the current working directory\n",
    "file_path = \"../data/raw_analyst_ratings.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1407328 entries, 0 to 1407327\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1407328 non-null  int64 \n",
      " 1   headline    1407328 non-null  object\n",
      " 2   url         1407328 non-null  object\n",
      " 3   publisher   1407328 non-null  object\n",
      " 4   date        1407328 non-null  object\n",
      " 5   stock       1407328 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 64.4+ MB\n",
      "None\n",
      "Unnamed: 0    0\n",
      "headline      0\n",
      "url           0\n",
      "publisher     0\n",
      "date          0\n",
      "stock         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Check the column names and data types\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Normalize Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by date (optional but useful for alignment)\n",
    "data = data.sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                                           headline  \\\n",
      "879310       883755                       How Treasuries and ETFs Work   \n",
      "519806       522587      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "1390006     1396488      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "1432           1834                             Going Against the Herd   \n",
      "67712         68387  Charles Sizemore Radio Interview Saturday Morning   \n",
      "\n",
      "                                                       url  \\\n",
      "879310   https://www.benzinga.com/28044/how-treasuries-...   \n",
      "519806   https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "1390006  https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "1432     https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "67712    https://www.benzinga.com/11218/charles-sizemor...   \n",
      "\n",
      "                          publisher                      date stock  \n",
      "879310                 Paco Ahlgren 2009-02-14 00:00:00+00:00   NAV  \n",
      "519806   Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00    FT  \n",
      "1390006  Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00     Y  \n",
      "1432     Charles Lewis Sizemore CFA 2009-04-29 00:00:00+00:00     A  \n",
      "67712    Charles Lewis Sizemore CFA 2009-05-22 00:00:00+00:00    AM  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format, handling any errors by coercing them\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce', utc=True)\n",
    "\n",
    "# Sort the data by date\n",
    "data = data.sort_values('date')\n",
    "\n",
    "# Verify the changes\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define a function to get sentiment polarity\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(text):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Define a function to get sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply the sentiment function to each headline\n",
    "data['sentiment'] = data['headline'].apply(get_sentiment)\n",
    "\n",
    "# Check the first few rows to confirm the sentiment column has been added\n",
    "print(data[['headline', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aggregate Daily Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sample DataFrame (replace this with your actual data)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGood news for the market\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBad news for stocks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket remains stable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-01-02\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m })  \u001b[38;5;66;03m# Ensure this is properly formatted\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Sample DataFrame (replace this with your actual data)\n",
    "data = pd.DataFrame({\n",
    "    'Unnamed: 0': [1, 2, 3],\n",
    "    'headline': ['Good news for the market', 'Bad news for stocks', 'Market remains stable'],\n",
    "    'date': ['2023-01-01', '2023-01-01', '2023-01-02'],\n",
    "    'stock': ['AAPL', 'AAPL', 'AAPL']\n",
    "})  # Ensure this is properly formatted\n",
    "\n",
    "# Function to calculate sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis to headlines\n",
    "data['sentiment'] = data['headline'].apply(get_sentiment)\n",
    "\n",
    "# Group by 'date' and calculate the mean sentiment score\n",
    "daily_sentiment = data.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "daily_sentiment.columns = ['date', 'average_sentiment']\n",
    "\n",
    "# Check the results\n",
    "print(daily_sentiment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate Daily Stock Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date  stock  stock_returns\n",
      "879310  2009-02-14 00:00:00+00:00    NaN            NaN\n",
      "519806  2009-04-27 00:00:00+00:00    NaN            NaN\n",
      "1390006 2009-04-27 00:00:00+00:00    NaN            NaN\n",
      "1432    2009-04-29 00:00:00+00:00    NaN            NaN\n",
      "67712   2009-05-22 00:00:00+00:00    NaN            NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP 830 G6\\AppData\\Local\\Temp\\ipykernel_21572\\435945514.py:7: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data['stock_returns'] = data['stock'].pct_change() * 100\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'stock' column is in numeric format (in case it's stored as strings)\n",
    "data['stock'] = pd.to_numeric(data['stock'], errors='coerce')\n",
    "\n",
    "# Check if the 'stock' column exists\n",
    "if 'stock' in data.columns:\n",
    "    # Calculate daily stock returns as percentage change\n",
    "    data['stock_returns'] = data['stock'].pct_change() * 100\n",
    "else:\n",
    "    print(\"Stock column not found.\")\n",
    "    \n",
    "# Check the first few rows to confirm the stock returns are calculated\n",
    "print(data[['date', 'stock', 'stock_returns']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Sentiment Data with Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  stock_price  sentiment_score\n",
      "0 2023-01-01          150              0.1\n",
      "1 2023-01-02          152              0.2\n",
      "2 2023-01-03          153             -0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames (replace these with your actual data)\n",
    "# Example DataFrame for stock prices\n",
    "data = pd.DataFrame({\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "    'stock_price': [150, 152, 153]\n",
    "})\n",
    "\n",
    "# Example DataFrame for sentiment analysis results\n",
    "daily_sentiment = pd.DataFrame({\n",
    "    'date': ['2023-01-01', '2023-01-02', '2023-01-03'],\n",
    "    'sentiment_score': [0.1, 0.2, -0.1]\n",
    "})\n",
    "\n",
    "# Ensure the 'date' columns are in datetime format for proper merging\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])\n",
    "\n",
    "# Merge sentiment and stock data on 'date'\n",
    "merged_data = pd.merge(data, daily_sentiment, on='date')\n",
    "\n",
    "# Inspect the merged data\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Column names in the dataset: Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n",
      "Missing necessary columns: 'stock', 'sentiment', or 'date'. Please check your data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Load the data (adjust file path as necessary)\n",
    "    data = pd.read_csv('../data/raw_analyst_ratings.csv')  # Replace with your actual file path\n",
    "    print(\"Data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Print the column names to inspect them\n",
    "print(\"Column names in the dataset:\", data.columns)\n",
    "\n",
    "# Check if the necessary columns exist\n",
    "if 'stock' in data.columns and 'sentiment' in data.columns and 'date' in data.columns:\n",
    "    # Step 1: Calculate daily returns\n",
    "    data['Daily_Return'] = data['stock'].pct_change() * 100\n",
    "\n",
    "    # Step 2: Ensure 'date' is in datetime format\n",
    "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "\n",
    "    # Step 3: Group by 'date' and calculate average sentiment for each day\n",
    "    daily_sentiment = data.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    daily_sentiment.columns = ['date', 'Average_Sentiment']\n",
    "\n",
    "    # Step 4: Merge sentiment and stock returns data on 'date'\n",
    "    merged_data = pd.merge(data, daily_sentiment, on='date')\n",
    "\n",
    "    # Step 5: Calculate Pearson correlation\n",
    "    correlation = merged_data['Daily_Return'].corr(merged_data['Average_Sentiment'])\n",
    "\n",
    "    # Step 6: Print the correlation result\n",
    "    print(f\"The correlation between sentiment and stock returns is: {correlation}\")\n",
    "else:\n",
    "    print(\"Missing necessary columns: 'stock', 'sentiment', or 'date'. Please check your data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
